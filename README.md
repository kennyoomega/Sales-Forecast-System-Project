# Sales Forecast System (v1.5 â€” FastAPI + Frontend + PostgreSQL Logging)

A full-stack retail analytics MVP built on Kaggleâ€™s Superstore dataset.

**New in v1.5:** added PostgreSQL logging â€” every forecast request (model, lags, prediction) is now stored in a relational database for audit, monitoring, and future BI dashboards. 

Scope: Python EDA â†’ forecasting â†’ API â†’ frontend â†’ database logging â†’ BI â†’ Azure deployment.

---

## âœ¨ Whatâ€™s new in v1.5

### Compared with v1.3/v1.4 (FastAPI + Frontend), this version v1.5 adds persistence
- ðŸ—„ï¸ PostgreSQL integration â€” requests & predictions logged into a forecast_logs table
- ðŸ“ Stored fields: model, lag1/lag2/lag3, prediction, created_at
- ðŸ”Ž `/logs/latest` endpoint â€” fetch recent logs directly from API
- ðŸŽ›ï¸ Frontend update â€” new â€œShow Logsâ€ button to view recent predictions in a table
- ðŸ”’ Keeps full history â†’ ready for Power BI (v1.6) and cloud deploy (v1.7)

---

## ðŸ–¼ï¸ Screenshots (v1.5)

- Frontend UI with forecast + logs

- API Swagger UI showing `/logs/latest`

---

## Quickstart (v1.5)

### 1. Train & save models (v1.2)
```powershell
# RandomForest
python src/eda_v1.2.py --input data/Superstore.csv --outdir reports --title "Retail EDA â€” MVP 1.2"

# XGBoost
python src/eda_v1.2.py --input data/Superstore.csv --outdir reports --title "Retail EDA â€” MVP 1.2 (XGB)" --model xgb
```

### 2. Setup PostgreSQL (v1.5)
```bash
-- Create database
CREATE DATABASE salesdb;

-- Run init_db() once to create tables
python -c "from src.db import init_db; init_db()"
```


### 3. Start FastAPI backend (with DB logging)
```bash
uvicorn src.api_v1_5:app --reload --port 8000
```

Endpoints:

Â· `/predict` â†’ forecast + log result

Â· `/logs/latest` â†’ fetch recent N logs

Â· `/docs` â†’ Swagger auto-docs

### 4. Start Next.js frontend (v1.4+v1.5)
```bash
cd frontend
npm install
npm run dev
```
Runs at: http://localhost:3000

Make sure `.env.local` contains:
```bash
NEXT_PUBLIC_API_BASE_URL=http://127.0.0.1:8000
```
---

## Roadmap (iteration plan)

- [x] **1.0 â€” MVP**: Normalise CSV â†’ KPIs â†’ Monthly & Category charts â†’ HTML report
- [x] **1.1 â€” Enhanced EDA**: Winsorisation, weekly/monthly aggregation, Topâ€‘N, geo, profit contribution
- [x] **1.2 â€” Forecasting**: Monthly aggregate â†’ RF/XGBoost â†’ *Actual vs Forecast* chart â†’ save model
- [x] **1.3 â€” FastAPI**: `/predict` endpoint returning JSON forecasts
- [x] **1.4 â€” Next.js**: horizon input â†’ call API â†’ render charts
- [x] **1.5 â€” PostgreSQL**: store forecasts & request logs
- [ ] **1.6 â€” Power BI**: direct PG connection for KPI dashboards
- [ ] **1.7 â€” Cloud deployment**: Azure (API + DB, EU region), Vercel/Azure SWA (frontend)
- [ ] **Final**: screenshots, architecture diagram, CI/CD, online demo

---

## Architecture (current â†’ target)

**Now (v1.5)**
CSV â†’ Forecast (RF/XGB) â†’ Model.pkl â†’ FastAPI API â†’ Next.js frontend â†’ **PostgreSQL logs**

**Target**  
```text
CSV / DWH â”€â”€> EDA (1.0/1.1) â”€â”€> Forecast (1.2) â”€â”€> FastAPI (1.3)
                                   â”‚                   â”‚
                                   â–¼                   â–¼
                              PostgreSQL (1.5) â”€â”€> Power BI (1.6)
                                   â–²
                                   â”‚
                              Next.js (1.4)

Infra: Azure App Service/Container Apps + Azure Database for PostgreSQL + Vercel/Azure SWA (1.7)
```

---

## Project highlights

- End-to-end pipeline: from raw CSV â†’ EDA â†’ forecasting â†’ API â†’ frontend â†’ DB logging
- Supports both RandomForest (baseline) and XGBoost, with reloadable saved models
- FastAPI backend now logs every forecast to PostgreSQL
- Next.js frontend extended with logs table for transparency
- Ready for BI dashboards (Power BI v1.6) and enterprise-style cloud deployment (Azure v1.7)

---

## ðŸ“‚ Project structure

```text
.
â”œâ”€ .github/
â”‚  â””â”€ workflows/
â”‚     â””â”€ smoke.yml      # Minimal CI (import + dependency check)
â”œâ”€ assets/              # Screenshots used in README (KPI, Weekly, Forecast, etc.)
â”œâ”€ data/                # Input data (Superstore.csv - not committed to Git)
â”œâ”€ frontend/            # v1.4 Next.js frontend app
â”‚  â”œâ”€ app/
â”‚  â”‚  â””â”€ page.tsx       # Main UI (inputs + forecast + logs)
â”‚  â”œâ”€ package.json
â”‚  â””â”€ .env.local (gitignored)
â”œâ”€ reports/             # Generated reports, figures, models (gitignored)
â”‚  â”œâ”€ figures/          # All PNG charts
â”‚  â””â”€ models/           # Saved ML models (.pkl)
â”œâ”€ scripts/
â”‚  â”œâ”€ run_eda.sh        # macOS/Linux helper
â”‚  â”œâ”€ run_eda.ps1       # Windows PowerShell helper
â”œâ”€ src/
â”‚  â”œâ”€ eda_v1.0.py       # v1.0 script (MVP)
â”‚  â”œâ”€ eda_v1.1.py       # v1.1 script (Enhanced EDA)
â”‚  â””â”€ eda_v1.2.py       # v1.2 script (Forecasting with RF/XGB)
â”‚  â””â”€ api_v1_3.py       # v1.3 FastAPI backend
â”‚  â”œâ”€ api_v1_5.py         # v1.5 FastAPI backend (DB logging)
â”‚  â””â”€ db.py               # SQLAlchemy models + Session
â”œâ”€ requirements.txt       # Python dependencies (now includes psycopg2, sqlalchemy, python-dotenv)
â”œâ”€ LICENSE              # MIT License
â””â”€ README.md            # Project documentation


```

---

## Dataset & licence

- Dataset: Kaggle *Sample Superstore* (public demo dataset)
- Intended for learning & portfolio use; not production
- Licence: MIT
