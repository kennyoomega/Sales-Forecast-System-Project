# Sales Forecast System (v1.6 â€” Power BI Dashboard)

A full-stack retail analytics MVP built on Kaggleâ€™s Superstore dataset.

**New in v1.6:** integrated **Power BI dashboards** â€” PostgreSQL logs (from v1.5) are now visualized in interactive reports with KPIs, trend lines, model mix, and detailed logs.

Scope: Python EDA â†’ forecasting â†’ API â†’ frontend â†’ database logging â†’ **BI dashboards** â†’ Azure deployment.

---

## âœ¨ Whatâ€™s new in v1.6

### Compared with v1.5 (FastAPI + DB logging), this version v1.6 adds visualization
- ðŸ“Š Power BI integration â€” connected directly to PostgreSQL `forecast_logs`
- ðŸ“ˆ KPIs â€” Total Predictions, Last Prediction value
- â³ Trend line â€” prediction values over time (continuous axis, average of predictions)
- ðŸ¥§ Donut chart â€” model usage ratio (RF vs XGB)
- ðŸ“‹ Log table â€” last 20 predictions with lags & results
- ðŸŽ›ï¸ Slicer â€” interactive filter to switch between RF / XGB
---

## ðŸ–¼ï¸ Screenshots (v1.6)

- **Dashboard Overview** (KPI cards + trend + model ratio + logs)

![Dashboard Overview](assets/pbi_overview.png)

- **Model Ratio (RF vs XGB)**

![Model Ratio](assets/pbi_model_ratio.png) 

- **Prediction Logs Table**

![Prediction Logs Table](assets/pbi_logs_table.png) 

---

## Quickstart (v1.6)

### 1. Ensure DB logging is active (from v1.5)
```powershell

uvicorn src.api_v1_5:app --reload --port 8000

```

Forecast requests will be logged to PostgreSQL in the `forecast_logs` table.

### 2. Connect Power BI to PostgreSQL

- Open Power BI Desktop â†’ Get Data â†’ PostgreSQL database

- Server: `localhost`, Database: `salesdb`

- Select table: `public.forecast_logs`

- Load data (optionally via Power Query for type casting)

### 3. Build dashboard visuals

- Card â†’ Total Predictions (`id` count)

- Card â†’ Last Prediction (`prediction` max by created_at)

- Line chart â†’ X=`created_at`, Y=`prediction (Average)`

- Donut chart â†’ Legend=`model`, Values=`id` count

- Table â†’ Columns: created_at, model, lags, prediction

- Slicer â†’ model (single select, RF vs XGB)

### 4. Save and export

Save the .pbix file locally.

---

## Roadmap (iteration plan)

- [x] **1.0 â€” MVP**: Normalise CSV â†’ KPIs â†’ Monthly & Category charts â†’ HTML report
- [x] **1.1 â€” Enhanced EDA**: Winsorisation, weekly/monthly aggregation, Topâ€‘N, geo, profit contribution
- [x] **1.2 â€” Forecasting**: Monthly aggregate â†’ RF/XGBoost â†’ *Actual vs Forecast* chart â†’ save model
- [x] **1.3 â€” FastAPI**: `/predict` endpoint returning JSON forecasts
- [x] **1.4 â€” Next.js**: horizon input â†’ call API â†’ render charts
- [x] **1.5 â€” PostgreSQL**: store forecasts & request logs
- [x] **1.6 â€” Power BI**: direct PG connection for KPI dashboards
- [ ] **1.7 â€” Cloud deployment**: Azure (API + DB, EU region), Vercel/Azure SWA (frontend)
- [ ] **Final**: screenshots, architecture diagram, CI/CD, online demo

---

## Architecture (current â†’ target)

**Now (v1.6)**
CSV â†’ Forecast (RF/XGB) â†’ Model.pkl â†’ FastAPI API â†’ Next.js frontend â†’ PostgreSQL logs â†’ **Power BI dashboards**

**Target**  
```text
CSV / DWH â”€â”€> EDA (1.0/1.1) â”€â”€> Forecast (1.2) â”€â”€> FastAPI (1.3)
                                   â”‚                   â”‚
                                   â–¼                   â–¼
                              PostgreSQL (1.5) â”€â”€> Power BI (1.6)
                                   â–²
                                   â”‚
                              Next.js (1.4)

Infra: Azure App Service/Container Apps + Azure Database for PostgreSQL + Vercel/Azure SWA (1.7)
```

---

## Project highlights

- End-to-end pipeline: raw CSV â†’ EDA â†’ ML forecasting â†’ API â†’ frontend â†’ DB logging â†’ BI dashboards
- PostgreSQL provides persistence; Power BI adds professional-grade visualization
- KPI cards, trends, model usage ratio, and detailed logs all in one view
- Dashboard design follows business standards: top KPIs â†’ trends â†’ ratios â†’ detail table â†’ slicer filter
- Ready for cloud deployment with Azure + Vercel

---

## ðŸ“‚ Project structure

```text
.
â”œâ”€ .github/
â”‚  â””â”€ workflows/
â”‚     â””â”€ smoke.yml      # Minimal CI (import + dependency check)
â”œâ”€ assets/              # Screenshots (Overview, Model Ratio, Logs Table)
â”œâ”€ data/                # Input data (Superstore.csv - not committed to Git)
â”œâ”€ frontend/            # v1.4 Next.js frontend app
â”‚  â”œâ”€ app/
â”‚  â”‚  â””â”€ page.tsx       # Main UI (inputs + forecast + logs)
â”‚  â”œâ”€ package.json
â”‚  â””â”€ .env.local (gitignored)
â”œâ”€ reports/             # Generated reports, figures, models (gitignored)
â”‚  â”œâ”€ figures/          # All PNG charts
â”‚  â””â”€ models/           # Saved ML models (.pkl)
â”œâ”€ scripts/
â”‚  â”œâ”€ run_eda.sh        # macOS/Linux helper
â”‚  â”œâ”€ run_eda.ps1       # Windows PowerShell helper
â”œâ”€ src/
â”‚  â”œâ”€ eda_v1.0.py       # v1.0 script (MVP)
â”‚  â”œâ”€ eda_v1.1.py       # v1.1 script (Enhanced EDA)
â”‚  â””â”€ eda_v1.2.py       # v1.2 script (Forecasting with RF/XGB)
â”‚  â””â”€ api_v1_3.py       # v1.3 FastAPI backend
â”‚  â”œâ”€ api_v1_5.py       # v1.5 FastAPI backend (DB logging)
â”‚  â””â”€ db.py             # SQLAlchemy models + Session
â”œâ”€ requirements.txt     # Python dependencies (now includes psycopg2, sqlalchemy, python-dotenv)
â”œâ”€ LICENSE              # MIT License
â””â”€ README.md            # Project documentation


```

---

## Dataset & licence

- Dataset: Kaggle *Sample Superstore* (public demo dataset)
- Intended for learning & portfolio use; not production
- Licence: MIT
